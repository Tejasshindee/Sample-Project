{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a764ad5-5ee9-47d1-8c5d-a7fd0de87015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/hadoop/.local/lib/python3.10/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33e15c16-509e-4ed3-808a-38bdbf56edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import findspark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4ce80-4211-4d4d-9dcd-0612a231c5cc",
   "metadata": {},
   "source": [
    "# Start PySpark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f718055-4966-4256-bbd3-784f4b8efce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 18:58:20 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc16f4-25a9-467c-bb69-9c3e43756f26",
   "metadata": {},
   "source": [
    "# Load the dataset into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd68159-511a-4f5e-8cdc-1a42cf86729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- product_id: long (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|2020-04-24 17:20:39|2294359932054536986|1515966223509089906|2268105426648170900|  electronics.tablet|samsung|162.01|1515915625441993984|\n",
      "|2020-04-24 17:20:39|2294359932054536986|1515966223509089906|2268105426648170900|  electronics.tablet|samsung|162.01|1515915625441993984|\n",
      "|2020-04-24 20:07:43|2294444024058086220|2273948319057183658|2268105430162997728|electronics.audio...| huawei| 77.52|1515915625447879434|\n",
      "|2020-04-24 20:07:43|2294444024058086220|2273948319057183658|2268105430162997728|electronics.audio...| huawei| 77.52|1515915625447879434|\n",
      "|2020-04-25 00:46:21|2294584263154074236|2273948316817424439|2268105471367840086|                NULL|karcher|217.57|1515915625443148002|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"purchase.csv\"\n",
    "purchase_df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display the schema and first few rows of the DataFrame\n",
    "purchase_df.printSchema()\n",
    "purchase_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ad9c6c-c816-4db7-b3f5-c80d2f3fe643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2633521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row_count = purchase_df.count()\n",
    "\n",
    "print(row_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33078464-1e43-469a-8573-e4f5c56a5d79",
   "metadata": {},
   "source": [
    "# Drop dulplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30bdbf56-ef7a-4c2f-8e9a-dd9cf297b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_df = purchase_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce921f2-d8b4-475f-a95b-e6215c2eb89b",
   "metadata": {},
   "source": [
    "# Count number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05762dc-664d-44d7-9ae3-71f9035da893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 18:03:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:03:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 21:=========================>                                (4 + 5) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2632846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row_count = purchase_df.count()\n",
    "\n",
    "print(row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3717074a-94a7-4c74-b398-fb7e76b9ce33",
   "metadata": {},
   "source": [
    "# Datatype of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1299f25-053c-4861-a37a-4c11bd9f72eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'bigint'),\n",
       " ('product_id', 'bigint'),\n",
       " ('category_id', 'bigint'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7939538-8da3-433e-833e-7fc64f1be606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[event_time: timestamp, order_id: bigint, product_id: bigint, category_id: bigint, category_code: string, brand: string, price: double, user_id: bigint]\n"
     ]
    }
   ],
   "source": [
    "print(purchase_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910098a-cedf-4189-96e0-37120527bb6f",
   "metadata": {},
   "source": [
    "# Filter out rows where price is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "814d7db8-d21a-4017-b025-9e3e0af4d6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 18:21:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 28:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_df = purchase_df.filter(purchase_df[\"price\"].isNotNull())\n",
    "filtered_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf883b1d-a0bb-4a8e-9f7e-764730eb7210",
   "metadata": {},
   "source": [
    "# Rows after deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f86eebc-6e9d-4e9f-927e-c046f1c7d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 18:22:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/13 18:22:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 31:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rc = filtered_df.count()\n",
    "\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc74c5-cd9d-49fc-87e7-9cf7ee2cd3fe",
   "metadata": {},
   "source": [
    "# Filter out rows where brand is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ee55376-6e14-4af9-a52a-bef4df965e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_df = filtered_df.filter(filtered_df[\"brand\"].isNotNull())\n",
    "\n",
    "filtered_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b0d5b-894e-45fb-a0d6-b834d3a4b2b2",
   "metadata": {},
   "source": [
    "# Rows after deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85ebc870-8a7c-490c-90f2-cd0f552591c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rc = filtered_df.count()\n",
    "\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32defe32-ba6a-4367-8d31-e150bf7f540d",
   "metadata": {},
   "source": [
    "# Inconsistent Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecc4fbe2-3c59-457b-89c3-049ba014ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with inconsistent event_time: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "# Group by 'order_id' and count the distinct 'event_time' values\n",
    "grouped_df = filtered_df.groupBy('order_id').agg(countDistinct('event_time').alias('num_distinct_event_time'))\n",
    "\n",
    "# Filter for inconsistent order ids where the number of distinct event times is greater than 1\n",
    "inconsistent_order_ids = grouped_df.filter(col('num_distinct_event_time') > 1).select('order_id')\n",
    "\n",
    "# Join with filtered_df to get the records with inconsistent event_time\n",
    "inconsistent_records = filtered_df.join(inconsistent_order_ids, 'order_id', 'inner')\n",
    "\n",
    "# Count the number of inconsistent records\n",
    "num_inconsistent_records = inconsistent_records.count()\n",
    "\n",
    "print(\"Number of records with inconsistent event_time:\", num_inconsistent_records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd836166-8e83-4b6e-be12-5971ccec1f6b",
   "metadata": {},
   "source": [
    "# Unique User IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59d090a2-9ad6-4772-ac35-1ea342f75234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user_id: 229229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = filtered_df# Count the number of unique user_id\n",
    "unique_user_count = df.select(\"user_id\").distinct().count()\n",
    "\n",
    "# Display the count of unique user_id\n",
    "print(unique_user_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed27b6d-436c-4403-99bc-c43e011077ab",
   "metadata": {},
   "source": [
    "# Unique Order IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05006d70-9e05-4c16-9e2a-61df7af42ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user_id: 1376122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_order_count = df.select(\"order_id\").distinct().count()\n",
    "\n",
    "# Display the count of unique user_id\n",
    "print(unique_order_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba3ada-29d5-4a9a-bbdb-0ffc263adf19",
   "metadata": {},
   "source": [
    "# Inconsistent order ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24a3cdaa-8a81-443d-a53e-cfb857cb4478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:===================>                                      (3 + 6) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows where each duplicate order_id does not have the same user_id: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Step 1: Identify duplicate order_id entries\n",
    "duplicate_orders_df = df.groupBy(\"order_id\").count().where(F.col(\"count\") > 1)\n",
    "\n",
    "# Step 2: Group by order_id and count distinct user_id values\n",
    "distinct_user_count_df = df.groupBy(\"order_id\").agg(F.countDistinct(\"user_id\").alias(\"distinct_user_count\"))\n",
    "\n",
    "# Step 3: Filter out groups where there is more than one distinct user_id\n",
    "filtered_orders_df = distinct_user_count_df.join(duplicate_orders_df, \"order_id\", \"inner\").filter(\"distinct_user_count > 1\")\n",
    "\n",
    "# Step 4: Count the total number of rows in the filtered DataFrame\n",
    "total_rows_with_different_user_id = filtered_orders_df.select(F.sum(\"count\")).collect()[0][0]\n",
    "\n",
    "# Display the result\n",
    "print(\"Total number of rows where each duplicate order_id does not have the same user_id:\", total_rows_with_different_user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b317664-616c-4d99-9d56-bbba4a6b77a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc19eba-4a42-474a-8679-a818ae7a3556",
   "metadata": {},
   "source": [
    "# Calculate the number of null values for each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6df82b21-5a45-4a85-9a9e-f541187ad78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|         0|       0|         0|          0|       556588|    0|    0|1551952|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in df.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = df.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f760f8-8a8b-44c1-b340-de50156b2d1a",
   "metadata": {},
   "source": [
    "# Calculate the number of null values in the \"category_id\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f86d8df-9285-4f1f-b9e6-f2124fa935a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in the 'category_id' column: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "null_category_id_count = df.select(sum(col(\"category_id\").isNull().cast(\"int\"))).collect()[0][0]\n",
    "\n",
    "# Display the number of null values in the \"category_id\" column\n",
    "print(\"Number of null values in the 'category_id' column:\", null_category_id_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "407bb9b3-2789-4e5d-8ab2-bd0c6e5f5d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'bigint'),\n",
       " ('product_id', 'bigint'),\n",
       " ('category_id', 'bigint'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87e0186a-0e25-4ef2-ae40-e9f871fdefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rc = df.count()\n",
    "\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38150d-c7b5-4ce0-afb5-f98df433e98c",
   "metadata": {},
   "source": [
    "# Filter out rows where category_code is not null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fb94aee-b1c4-400e-a270-334e681b290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fdf = df.filter(df[\"category_code\"].isNotNull())\n",
    "\n",
    "fdf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4351d29-afde-4ead-8dea-3c69120cba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 122:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rc = fdf.count()\n",
    "\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c57121-8d07-496f-9d8f-e03427a95e1e",
   "metadata": {},
   "source": [
    "# Count unique records in category_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44440be4-405c-45cd-a07c-552f1cf541c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 149:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "distinct_category_code_count = df.select(countDistinct(\"category_code\")).collect()[0][0]\n",
    "\n",
    "print(distinct_category_code_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5416cb7c-9d87-4e3f-a6ed-d539315b27c1",
   "metadata": {},
   "source": [
    "# count the distinct records before the first dot '.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84b76e89-8616-4bb8-a522-6d50965cc49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 140:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct records before the first dot '.': 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# Extract the category before the first dot '.'\n",
    "df_with_category = fdf.withColumn(\"category_before_dot\", split(col(\"category_code\"), \"\\\\.\")[0])\n",
    "\n",
    "# Count the distinct records before the first dot '.'\n",
    "distinct_category_before_dot_count = df_with_category.select(\"category_before_dot\").distinct().count()\n",
    "\n",
    "# Display the count of distinct records before the first dot '.'\n",
    "print(\"Number of distinct records before the first dot '.':\", distinct_category_before_dot_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97c3ff-c38a-4b66-94d8-d03fc576f77d",
   "metadata": {},
   "source": [
    "# Display the distinct names of records before the first dot '.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5be83ea6-3ae7-4084-a54a-21b0519fa89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct names of records before the first dot '.' in the 'category_code' column:\n",
      "medicine\n",
      "computers\n",
      "auto\n",
      "stationery\n",
      "sport\n",
      "apparel\n",
      "appliances\n",
      "country_yard\n",
      "furniture\n",
      "accessories\n",
      "kids\n",
      "electronics\n",
      "construction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# Extract the category before the first dot '.'\n",
    "df_with_category = fdf.withColumn(\"category_before_dot\", split(col(\"category_code\"), \"\\\\.\")[0])\n",
    "\n",
    "# Select and display the distinct names of records before the first dot '.'\n",
    "distinct_category_before_dot_names = df_with_category.select(\"category_before_dot\").distinct().collect()\n",
    "distinct_category_before_dot_names = [row[\"category_before_dot\"] for row in distinct_category_before_dot_names]\n",
    "\n",
    "print(\"Distinct names of records before the first dot '.' in the 'category_code' column:\")\n",
    "for name in distinct_category_before_dot_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19af980-3032-480b-b5a3-3dff96148199",
   "metadata": {},
   "source": [
    "# Count Records that start with 'string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7d487c1-c6ea-4185-9f21-70c5b442ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 155:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('medicine')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e249868-caf6-46e3-b473-0249706652cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('computers')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fa7fdab-2442-4dcb-b3d8-7889cd2ed4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('auto')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "391a2570-971f-4282-b639-9678cfb2e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 173:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('stationery')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "015b5ed0-3352-49fa-ba4f-53215805072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 179:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('sport')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec1d297b-afa6-40e3-8c3e-07e1d6f4e289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 185:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('apparel')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23a598fd-585f-4cf7-bc92-ae94d16a8a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 191:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('appliances')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8af47274-11ce-4d5b-8841-a3fb864f6c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 197:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('country_yard')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e388c9a4-e126-41fc-8874-d09a6894be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 203:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('furniture')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7921bbd-6711-4fab-ae0e-5ff2817283f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 209:============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('accessories')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11f3602a-2bb4-47ea-bcc1-c3c79454ff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 215:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('kids')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ad9b869-11a1-409a-8189-b0e518ec5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 221:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('electronics')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aab33ab3-f944-4b56-a8d5-37b49ffbfd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 230:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "category_code_count = df.filter(col(\"category_code\").startswith('construction')).count()\n",
    "\n",
    "print(category_code_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a01e2d-62d2-4d81-93ff-9e2ea7ada654",
   "metadata": {},
   "source": [
    "# Download clean data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f64a82b-d8b1-47cd-95fc-6e23c8cdfc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Specify the path where you want to save the cleaned CSV file\n",
    "output_path = \"clean_file\"\n",
    "\n",
    "# Write the cleaned DataFrame to a single CSV file\n",
    "df.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615a2a3-5f3a-48e6-b7b1-c0ab26f4775d",
   "metadata": {},
   "source": [
    "# Download cleaned file w/o any null records in category_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffb822fd-212f-4ad2-81fd-f9f276799cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Specify the path where you want to save the cleaned CSV file\n",
    "output_path = \"filered_clean_file\"\n",
    "\n",
    "# Write the cleaned DataFrame to a single CSV file\n",
    "fdf.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72103b0c-07ed-4464-b4f5-866adef8e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"filtered_clean.csv\"\n",
    "fdf1 = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "085bf741-6af7-4d10-8876-a3db5013eb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531675\n"
     ]
    }
   ],
   "source": [
    "rc = fdf1.count()\n",
    "\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14a3d108-9ee6-4ce2-b6f0-2238d4de8302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|         0|       0|         0|          0|            0|    0|    0|1111457|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in fdf1.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = fdf1.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da148690-aeeb-429a-84dd-b01a2c3f34ff",
   "metadata": {},
   "source": [
    "# Load dataset into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e023b4cc-8fff-4841-9266-01fa23fd0e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"clean_file.csv\"\n",
    "df1 = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0f7d32a9-d7b3-4d78-8b76-d598d0090e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088263\n",
      "2088263\n"
     ]
    }
   ],
   "source": [
    "rc = df.count()\n",
    "\n",
    "print(rc)\n",
    "\n",
    "rc = df1.count()\n",
    "\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8065eb7c-4b84-48be-a370-3ca10be7849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==============>                                            (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|         0|       0|         0|          0|       556588|    0|    0|1551952|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in df1.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = df1.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2dd1a-1205-495a-9c5b-61f20a5ddaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c6fb38e-f83d-4381-989f-fe2aa397d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_order_count = fdf1.select(\"order_id\").distinct().count()\n",
    "\n",
    "# Display the count of unique user_id\n",
    "print(unique_order_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0838cd6-3c3a-4f87-8826-ad6ac3fb87fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_order_count = fdf1.select(\"user_id\").distinct().count()\n",
    "\n",
    "# Display the count of unique user_id\n",
    "print(unique_order_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905c2887-36e0-4837-bde3-155c5f5c9bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'bigint'),\n",
       " ('product_id', 'bigint'),\n",
       " ('category_id', 'bigint'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994bbfba-94b0-4ec0-b0ab-84d1434a206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_order_count = fdf1.select(\"product_id\").distinct().count()\n",
    "\n",
    "# Display the count of unique user_id\n",
    "print(unique_order_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4198e344-320c-4908-87c9-d372dce1b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_order_count = fdf1.select(\"category_id\").distinct().count()\n",
    "\n",
    "# Display the count of unique user_id\n",
    "print(unique_order_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e934a-71d7-40c0-83bb-f5101694e262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "013ef66e-d5da-4af8-96ee-63bc8dfadf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with new column user_id1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 23:24:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:24:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:24:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:24:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:24:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:24:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+---------------+\n",
      "|           order_id|         event_time|         product_id|        category_id|       category_code|    brand| price|            user_id|       user_id1|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+---------------+\n",
      "|2298069964415828136|2020-04-29 20:11:49|1515966223509122874|2268105407933187062|computers.periphe...|       hp|152.52|1515915625443027224|911562541932228|\n",
      "|2300342008322982139|2020-05-02 23:25:58|2273948248047616169|2268105406549066706|computers.periphe...|    delux|  5.07|1515915625444068089|911562541947545|\n",
      "|2302886286089781416|2020-05-06 11:40:59|1515966223509089722|2268105441856717530|appliances.kitche...|      ava|  9.24|1515915625455413662|911562541942454|\n",
      "|2303774668819006287|2020-05-07 17:06:03|1515966223509104779|2268105428166508982|electronics.smart...|   huawei|277.75|1515915625455260153|911562541937250|\n",
      "|2303793094941737810|2020-05-07 17:42:39|1515966223509104342|2268105430162997728|electronics.audio...|   xiaomi| 25.44|1515915625455337062|911562541946153|\n",
      "|2306025363609748437|2020-05-10 19:37:46|1515966223509300544|2268105406691673046|computers.periphe...|     none|  2.75|1515915625455930757|911562541901818|\n",
      "|2347967420448113367|2020-07-07 16:29:09|1515966223509089268|2268105428166508982|electronics.smart...|  samsung|104.14|1515915625476666167|911562541950402|\n",
      "|2348772520296973173|2020-01-15 17:32:59|1515966223509089067|2268105428166508982|electronics.smart...|  samsung|138.87|               NULL|911562541985494|\n",
      "|2348778288463217655|2020-01-24 17:01:34|1515966223509089642|2268105439247860386|appliances.kitche...|      ava| 43.96|               NULL|911562541941152|\n",
      "|2348778460723282611|2020-01-24 11:17:05|1515966223509127837|2268105408293897214| stationery.cartrige|    canon|  9.24|               NULL|911562541983186|\n",
      "|2348778496576193380|2020-01-24 17:33:46|1515966223509089787|2268105389956399770|appliances.kitche...|  samsung| 300.9|               NULL|911562541951884|\n",
      "|2348778645650146017|2020-01-25 15:32:48|1515966223510207417|2268105438778098326|appliances.kitche...| peterhof|  2.75|               NULL|911562541995629|\n",
      "|2348789498655014982|2020-02-07 15:41:31|1515966223509107826|2268105428166508982|electronics.smart...|     oppo|231.23|               NULL|           NULL|\n",
      "|2348789924662084276|2020-02-08 14:23:47|1515966223509629976|2268105442636858090|furniture.kitchen...|  rondell| 15.02|               NULL|           NULL|\n",
      "|2348790043545436548|2020-02-08 12:00:37|1515966223509105054|2268105440220938934|appliances.kitche...|    tefal|115.72|               NULL|           NULL|\n",
      "|2348790057814458865|2020-02-09 10:32:52|1515966223509104973|2268105428250395064|electronics.telep...|panasonic| 29.14|               NULL|           NULL|\n",
      "|2348808396989268108|2020-03-01 18:52:54|1515966223509106172|2268105440220938934|appliances.kitche...|     bork|682.85|               NULL|           NULL|\n",
      "|2348808516937973893|2020-03-04 16:14:13|1515966223509089955|2268105441009468104|appliances.kitche...| moulinex| 57.85|               NULL|           NULL|\n",
      "|2348814239780569770|2020-03-08 12:28:11|1515966223509255467|2268105392070329020|appliances.enviro...|    tefal|127.29|               NULL|           NULL|\n",
      "|2348814498258747930|2020-03-07 16:33:53|1515966223509122879|2268105390174503582|appliances.sewing...|   janome|162.01|               NULL|           NULL|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "start_user_id = 911562541901000\n",
    "num_unique_user_ids = 100000\n",
    "\n",
    "# Generate random user_id1 values\n",
    "random_user_ids = spark.range(start_user_id, start_user_id + num_unique_user_ids).select(F.col(\"id\").cast(\"bigint\").alias(\"user_id1\"))\n",
    "\n",
    "# Create a DataFrame named df_cleaned (assuming it's already available)\n",
    "# Assuming df_cleaned has columns 'order_id' and 'user_id1'\n",
    "\n",
    "# Group by 'order_id' and get distinct values\n",
    "unique_order_ids = fdf1.select('order_id').distinct()\n",
    "\n",
    "# Assign random user_id1 to each unique order_id\n",
    "windowSpec = Window.orderBy(F.monotonically_increasing_id())\n",
    "random_user_ids = random_user_ids.withColumn(\"row_num\", F.row_number().over(windowSpec))\n",
    "\n",
    "# Join with unique order_ids\n",
    "mapped_user_ids = unique_order_ids.withColumn(\"row_num\", F.monotonically_increasing_id()).join(random_user_ids, on=\"row_num\", how=\"inner\").drop(\"row_num\")\n",
    "\n",
    "# Map order_id to user_id1\n",
    "fdf2 = fdf1.join(mapped_user_ids, on=\"order_id\", how=\"left\")\n",
    "\n",
    "# Show DataFrame\n",
    "print(\"DataFrame with new column user_id1:\")\n",
    "fdf2.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c3e8ba7-9e61-483c-b3b9-8d196574f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 23:25:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:25:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:25:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:25:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:26:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/02/13 23:26:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 67:>                                                         (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+--------+\n",
      "|order_id|event_time|product_id|category_id|category_code|brand|price|user_id|user_id1|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+--------+\n",
      "|       0|         0|         0|          0|            0|    0|    0|1111457| 1388443|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in fdf2.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = fdf2.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63858218-7283-4810-8a30-33697fafaddb",
   "metadata": {},
   "source": [
    "# Unique event_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620bff37-5f77-4fe7-8677-aa896597e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in the 'event_time' column: 1064860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the distinct values in the \"event_time\" column\n",
    "distinct_event_time_count = fdf1.select(\"event_time\").distinct().count()\n",
    "\n",
    "# Display the count of distinct values\n",
    "print(\"Number of distinct values in the 'event_time' column:\", distinct_event_time_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ab974f-ce6b-4b52-9c37-b75f51fd24ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in the 'order_id' column: 1143398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the distinct values in the \"event_time\" column\n",
    "distinct_event_time_count = fdf1.select(\"order_id\").distinct().count()\n",
    "\n",
    "# Display the count of distinct values\n",
    "print(\"Number of distinct values in the 'order_id' column:\", distinct_event_time_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73f101-b41b-4a4e-b011-ff4763054b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801e59e7-d096-4839-b70d-cbe1622f33d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088263\n"
     ]
    }
   ],
   "source": [
    "rc = df1.count()\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9f4938-3c4b-4647-a6da-fd5102d5decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74517c-80de-4dd5-b71a-8275a1049e55",
   "metadata": {},
   "source": [
    "# Count null values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c269d38-87a2-45ed-aca2-2a3b6744dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|         0|       0|         0|          0|       556588|    0|    0|1551952|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in df1.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = df1.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638593fa-b632-4596-8cdf-e8115638076d",
   "metadata": {},
   "source": [
    "# Assign 'other' in category_code where values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b42fbbad-1e77-4b58-b10d-a68c46adf277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Assign 'other' to null values in the \"category_code\" column\n",
    "odf = df1.withColumn(\"category_code\", when(df1[\"category_code\"].isNull(), \"other\").otherwise(df1[\"category_code\"]))\n",
    "\n",
    "# Show the updated DataFrame\n",
    "odf.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463d4b4-58f8-4896-9538-3921d8b010f8",
   "metadata": {},
   "source": [
    "# After assigning again check null values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e3cbed-9f85-42a8-9187-5c5bd0b61725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|         0|       0|         0|          0|            0|    0|    0|1551952|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in odf.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = odf.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421293b1-e1fe-45f0-8c07-d9e1acd05266",
   "metadata": {},
   "source": [
    "# Download file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0280d2ee-453d-473d-8b4d-db75421c9de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"other_clean_file\"\n",
    "\n",
    "odf.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a246e-3531-4071-afe6-d3686257b4a4",
   "metadata": {},
   "source": [
    "# Load file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8efbe8fa-5e31-4454-a516-679bc400e568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"other_clean.csv\"\n",
    "odf = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb08a9c-82dc-4baf-a53d-ea8dad584fcb",
   "metadata": {},
   "source": [
    "# Add new column name 'user_id1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bcab345-8f70-4d3a-8a77-7f7d7486fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-------------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|           user_id1|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-------------------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|1515915625443027224|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|1515915625445938216|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|1515915625446617606|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|1515915625452727322|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|1515915625452815830|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|1515915625452840817|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|1515915625441990819|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|1515915625444068089|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|1515915625452091416|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|1515915625455538086|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|1515915625455413662|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|1515915625454919094|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|1515915625455260153|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|1515915625455337062|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|1515915625454603469|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|1515915625457040117|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|1515915625497428278|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|1515915625457683949|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|1515915625455930757|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|1515915625457596219|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf = odf.withColumn(\"user_id1\", odf[\"user_id\"])\n",
    "\n",
    "cdf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d69bd3-85b2-4e83-a8bf-a7d73b310b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+--------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|user_id1|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+--------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|    NULL|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|    NULL|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606|    NULL|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|    NULL|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|    NULL|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|    NULL|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|    NULL|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|    NULL|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416|    NULL|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|    NULL|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662|    NULL|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094|    NULL|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|    NULL|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|    NULL|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|    NULL|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117|    NULL|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|    NULL|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|    NULL|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|    NULL|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219|    NULL|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "cdf1 = odf.withColumn(\"user_id1\", lit(None).cast(\"bigint\"))\n",
    "\n",
    "cdf1.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276cd930-e19c-462e-aa42-fb271b519b99",
   "metadata": {},
   "source": [
    "# Download cdf1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be510006-74b7-4329-b24f-4d6ca78aea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"cdf1_file\"\n",
    "\n",
    "cdf1.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef27db-147f-4774-aefe-6fbaa245ec1e",
   "metadata": {},
   "source": [
    "# Load cdf1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebd3c4c-aff2-4919-a30d-7775461bf473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"cdf1_file.csv\"\n",
    "cdf1 = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7f3c40b-3d01-47e6-a929-ea2a1ff5037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+--------+---------------+\n",
      "|           order_id|         event_time|         product_id|        category_id|       category_code|    brand| price|            user_id|user_id1|       user_id3|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+--------+---------------+\n",
      "|2298069964415828136|2020-04-29 20:11:49|1515966223509122874|2268105407933187062|computers.periphe...|       hp|152.52|1515915625443027224|    NULL|911562558747193|\n",
      "|2300342008322982139|2020-05-02 23:25:58|2273948248047616169|2268105406549066706|computers.periphe...|    delux|  5.07|1515915625444068089|    NULL|911562560279907|\n",
      "|2302886286089781416|2020-05-06 11:40:59|1515966223509089722|2268105441856717530|appliances.kitche...|      ava|  9.24|1515915625455413662|    NULL|911562552616904|\n",
      "|2303774668819006287|2020-05-07 17:06:03|1515966223509104779|2268105428166508982|electronics.smart...|   huawei|277.75|1515915625455260153|    NULL|911562555046666|\n",
      "|2303793094941737810|2020-05-07 17:42:39|1515966223509104342|2268105430162997728|electronics.audio...|   xiaomi| 25.44|1515915625455337062|    NULL|911562546198432|\n",
      "|2306025363609748437|2020-05-10 19:37:46|1515966223509300544|2268105406691673046|computers.periphe...|     none|  2.75|1515915625455930757|    NULL|911562546303366|\n",
      "|2308169134820557798|2020-05-13 18:37:04|2273948282583515178|2268105388421284472|appliances.kitche...|    bosch|370.35|1515915625441519412|    NULL|911562545529901|\n",
      "|2311685249441989473|2020-05-18 15:02:57|1515966223509104651|2268105410491711534|computers.compone...|transcend| 42.34|1515915625452923646|    NULL|911562551730477|\n",
      "|2311872513145045484|2020-05-18 21:15:01|1515966223509127814|2268105407933187062|computers.periphe...|       hp|136.32|1515915625440940103|    NULL|911562554667490|\n",
      "|2348775142777160643|2020-01-19 13:51:25|1515966223509629976|2268105442636858090|furniture.kitchen...|  rondell| 15.02|               NULL|    NULL|911562552793665|\n",
      "|2348775280862036749|2020-01-19 18:11:19|1515966223509090014|2268105430162997728|electronics.audio...|   bloody|  34.7|               NULL|    NULL|911562546722548|\n",
      "|2348777531718500574|2020-01-23 15:49:46|2273948299721441718|2268105411523510340|     accessories.bag|transcend|  6.92|               NULL|    NULL|911562550470701|\n",
      "|2348777707409506776|2020-01-24 10:31:35|2273948181223965148|2268105409048870926|computers.network...|  tp-link| 13.87|               NULL|    NULL|911562552666092|\n",
      "|2348777861407572278|2020-01-24 17:47:28|1515966223509088572|2268105407220155366|  computers.notebook|   lenovo|694.42|               NULL|    NULL|911562547034217|\n",
      "|2348777909767897796|2020-01-24 17:32:10|1515966223510051678|2268105439323357860|               other|      ava|277.75|               NULL|    NULL|911562549859847|\n",
      "|2348777978915192893|2020-01-24 17:11:44|1515966223509117573|2374498914000592282|electronics.video.tv|  samsung|532.38|               NULL|    NULL|911562550063300|\n",
      "|2348784446204805675|2020-02-01 18:08:10|1515966223509107017|2268105402983908234|appliances.person...|    vitek| 20.81|               NULL|    NULL|911562557564054|\n",
      "|2348796063663522682|2020-02-15 10:57:13|2273948311742316796|2268105393848713950|appliances.kitche...|       lg|462.94|               NULL|    NULL|911562561868885|\n",
      "|2348796078351975403|2020-02-15 17:03:59|1515966223509259408|2268105427260539298|               other|      ava|  2.29|               NULL|    NULL|911562554408374|\n",
      "|2348796219129594434|2020-02-14 20:07:27|1515966223509104324|2268105427260539298|               other|  samsung|  1.13|               NULL|    NULL|911562543535240|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, rand\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AssignUserIDs\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data - replace this with your actual DataFrame\n",
    "# df_cleaned = spark.createDataFrame([...], [\"order_id\", ...])\n",
    "\n",
    "# Generate a DataFrame with unique order_id and a random user_id1\n",
    "unique_order_ids = cdf1.select(\"order_id\").distinct()\n",
    "unique_order_ids = unique_order_ids.withColumn(\"user_id3\", (rand() * (911562561901000 - 911562541901000) + 911562541901000).cast(\"bigint\"))\n",
    "\n",
    "# Join the original DataFrame with the DataFrame containing unique order_id and user_id1\n",
    "udf = cdf1.join(unique_order_ids, \"order_id\", \"left\")\n",
    "\n",
    "# Show the DataFrame\n",
    "udf.show()\n",
    "\n",
    "# Stop SparkSession\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb07ae01-3402-4022-8b25-8c109b17c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"Userdf_file\"\n",
    "\n",
    "udf.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e6be71f-cd0f-490e-8d7f-d2add5b7d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in the 'user_id3' column: 1329754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the distinct values in the \"event_time\" column\n",
    "distinct_event_time_count = udf.select(\"user_id3\").distinct().count()\n",
    "\n",
    "# Display the count of distinct values\n",
    "print(\"Number of distinct values in the 'user_id3' column:\", distinct_event_time_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97b7ceee-41bf-49fc-bd69-5818cb5ef1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in the 'order_id' column: 1376122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the distinct values in the \"event_time\" column\n",
    "distinct_event_time_count = udf.select(\"order_id\").distinct().count()\n",
    "\n",
    "# Display the count of distinct values\n",
    "print(\"Number of distinct values in the 'order_id' column:\", distinct_event_time_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939c572-584a-426d-80ca-dfc2aaadbd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f1002d1-6043-41cf-b1d2-49903f5f9a16",
   "metadata": {},
   "source": [
    "# Create new user_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ac1b117-9c66-434b-bd32-07f19f794a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+--------+---------------+\n",
      "|           order_id|         event_time|         product_id|        category_id|       category_code|    brand| price|            user_id|user_id1|       user_id4|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+--------+---------------+\n",
      "|2298069964415828136|2020-04-29 20:11:49|1515966223509122874|2268105407933187062|computers.periphe...|       hp|152.52|1515915625443027224|    NULL|911562541902984|\n",
      "|2300342008322982139|2020-05-02 23:25:58|2273948248047616169|2268105406549066706|computers.periphe...|    delux|  5.07|1515915625444068089|    NULL|911562541938535|\n",
      "|2302886286089781416|2020-05-06 11:40:59|1515966223509089722|2268105441856717530|appliances.kitche...|      ava|  9.24|1515915625455413662|    NULL|911562541920980|\n",
      "|2303774668819006287|2020-05-07 17:06:03|1515966223509104779|2268105428166508982|electronics.smart...|   huawei|277.75|1515915625455260153|    NULL|911562541905574|\n",
      "|2303793094941737810|2020-05-07 17:42:39|1515966223509104342|2268105430162997728|electronics.audio...|   xiaomi| 25.44|1515915625455337062|    NULL|911562541942283|\n",
      "|2306025363609748437|2020-05-10 19:37:46|1515966223509300544|2268105406691673046|computers.periphe...|     none|  2.75|1515915625455930757|    NULL|911562541944304|\n",
      "|2308169134820557798|2020-05-13 18:37:04|2273948282583515178|2268105388421284472|appliances.kitche...|    bosch|370.35|1515915625441519412|    NULL|911562541901187|\n",
      "|2311685249441989473|2020-05-18 15:02:57|1515966223509104651|2268105410491711534|computers.compone...|transcend| 42.34|1515915625452923646|    NULL|911562541930023|\n",
      "|2311872513145045484|2020-05-18 21:15:01|1515966223509127814|2268105407933187062|computers.periphe...|       hp|136.32|1515915625440940103|    NULL|911562541904251|\n",
      "|2348775142777160643|2020-01-19 13:51:25|1515966223509629976|2268105442636858090|furniture.kitchen...|  rondell| 15.02|               NULL|    NULL|911562541935613|\n",
      "|2348775280862036749|2020-01-19 18:11:19|1515966223509090014|2268105430162997728|electronics.audio...|   bloody|  34.7|               NULL|    NULL|911562541934805|\n",
      "|2348777531718500574|2020-01-23 15:49:46|2273948299721441718|2268105411523510340|     accessories.bag|transcend|  6.92|               NULL|    NULL|911562541950561|\n",
      "|2348777707409506776|2020-01-24 10:31:35|2273948181223965148|2268105409048870926|computers.network...|  tp-link| 13.87|               NULL|    NULL|911562541935608|\n",
      "|2348777861407572278|2020-01-24 17:47:28|1515966223509088572|2268105407220155366|  computers.notebook|   lenovo|694.42|               NULL|    NULL|911562541937753|\n",
      "|2348777909767897796|2020-01-24 17:32:10|1515966223510051678|2268105439323357860|               other|      ava|277.75|               NULL|    NULL|911562541909569|\n",
      "|2348777978915192893|2020-01-24 17:11:44|1515966223509117573|2374498914000592282|electronics.video.tv|  samsung|532.38|               NULL|    NULL|911562541901381|\n",
      "|2348784446204805675|2020-02-01 18:08:10|1515966223509107017|2268105402983908234|appliances.person...|    vitek| 20.81|               NULL|    NULL|911562541940301|\n",
      "|2348796063663522682|2020-02-15 10:57:13|2273948311742316796|2268105393848713950|appliances.kitche...|       lg|462.94|               NULL|    NULL|911562541921689|\n",
      "|2348796078351975403|2020-02-15 17:03:59|1515966223509259408|2268105427260539298|               other|      ava|  2.29|               NULL|    NULL|911562541950959|\n",
      "|2348796219129594434|2020-02-14 20:07:27|1515966223509104324|2268105427260539298|               other|  samsung|  1.13|               NULL|    NULL|911562541902764|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+-------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, rand\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AssignUserIDs\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Generate a DataFrame with unique order_id and a random user_id1\n",
    "unique_order_ids = cdf1.select(\"order_id\").distinct()\n",
    "unique_order_ids = unique_order_ids.withColumn(\"user_id4\", (rand() * (50000) + 911562541901000).cast(\"bigint\"))\n",
    "\n",
    "# Join the original DataFrame with the DataFrame containing unique order_id and user_id1\n",
    "udf1 = cdf1.join(unique_order_ids, \"order_id\", \"left\")\n",
    "\n",
    "udf1.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d46c30d-4dec-4b77-8df7-3746b36cbbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in the 'order_id' column: 1376122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the distinct values in the \"event_time\" column\n",
    "distinct_event_time_count = udf1.select(\"order_id\").distinct().count()\n",
    "\n",
    "# Display the count of distinct values\n",
    "print(\"Number of distinct values in the 'order_id' column:\", distinct_event_time_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e88d717-0694-4f0d-ba03-9fe069f4db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in the 'user_id4' column: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the distinct values in the \"event_time\" column\n",
    "distinct_event_time_count = udf1.select(\"user_id4\").distinct().count()\n",
    "\n",
    "# Display the count of distinct values\n",
    "print(\"Number of distinct values in the 'user_id4' column:\", distinct_event_time_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b034e192-d46a-4513-9b07-615047781483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+--------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|user_id1|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+--------+\n",
      "|         0|       0|         0|          0|            0|    0|    0|1551952| 2088263|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in cdf1.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = cdf1.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d06220e4-326f-460b-a99b-326ff7c60e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/14 22:32:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:32:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:32:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+--------+--------+\n",
      "|order_id|event_time|product_id|category_id|category_code|brand|price|user_id|user_id1|user_id4|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+--------+--------+\n",
      "|       0|         0|         0|          0|            0|    0|    0|1551952| 2088263|       0|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in udf1.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = udf1.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90d14f66-bc23-46e2-a085-3cff401103a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf2 = udf1.drop(\"user_id\", \"user_id1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbd54a29-70db-488e-aa4e-39d2388f0de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/14 22:33:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:33:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:33:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:33:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 93:>                                                         (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-----------+-------------+-----+-----+--------+\n",
      "|order_id|event_time|product_id|category_id|category_code|brand|price|user_id4|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+--------+\n",
      "|       0|         0|         0|          0|            0|    0|    0|       0|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in udf2.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = udf2.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0611eefd-906c-4915-b2f0-1a59e782399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf3 = udf2.withColumnRenamed(\"user_id4\", \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c7d4f91-998f-4ad1-91e1-b13859cd9893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/14 22:35:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:35:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:35:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:35:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 102:>                                                        (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+\n",
      "|order_id|event_time|product_id|category_id|category_code|brand|price|user_id|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+\n",
      "|       0|         0|         0|          0|            0|    0|    0|      0|\n",
      "+--------+----------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in udf3.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = udf3.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d138abac-c7a4-433d-9b3b-ac32692e6223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"udf3_file\"\n",
    "\n",
    "udf3.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc527e5-18d0-4f7f-b608-0534f68ab896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('order_id', 'bigint'),\n",
       " ('event_time', 'timestamp'),\n",
       " ('product_id', 'bigint'),\n",
       " ('category_id', 'bigint'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9964d98-1a1e-4e83-be49-3c8b7e5ff8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088263\n"
     ]
    }
   ],
   "source": [
    "row_count = udf3.count()\n",
    "\n",
    "print(row_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48e00b25-77d1-48c2-95a6-690b8955286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 116:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user_id values: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "unique_user_count = udf3.select(countDistinct(\"user_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique user_id values:\", unique_user_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc342fe-165f-46b6-a8ba-06d5eb06363c",
   "metadata": {},
   "source": [
    "# Count unique Order IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22829e1c-8988-49be-a3f6-3e24b6592b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order_id values: 1376122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = udf3.select(countDistinct(\"order_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order_id values:\", uc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838de2b-d320-4f65-adc5-e65695e1b3e1",
   "metadata": {},
   "source": [
    "# Count unique event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903a4529-d83c-45b2-aa52-6dd0e5798d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique event_time values: 1265836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "unique_user_count = udf3.select(countDistinct(\"event_time\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique event_time values:\", unique_user_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea8532-7acc-46db-96a7-31b4eb8800e1",
   "metadata": {},
   "source": [
    "# inconsistent records where multiple duplicate order_id have multiple unique event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb9eaa52-98c6-4159-93a9-e8cb037c402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 143:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent records: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Group by order_id and count the distinct event_time values\n",
    "inconsistent_records_count = udf3.groupby(\"order_id\").agg(F.countDistinct(\"event_time\").alias(\"unique_event_times\"))\n",
    "\n",
    "# Filter for records where the count of unique event_time values is greater than 1\n",
    "inconsistent_records_count = inconsistent_records_count.filter(inconsistent_records_count[\"unique_event_times\"] > 1)\n",
    "\n",
    "# Count the number of inconsistent records\n",
    "num_inconsistent_records = inconsistent_records_count.count()\n",
    "\n",
    "# Display the number of inconsistent records\n",
    "print(\"Number of inconsistent records:\", num_inconsistent_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22577f-9118-4f03-92d0-dc2fc87f9311",
   "metadata": {},
   "source": [
    "#  inconsistent records where multiple duplicate event_time have multiple unique order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52ab27b5-b7ab-4b61-a9e9-d77ff80574e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 153:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent records: 89455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Group by event_time and count the distinct order_id values\n",
    "inconsistent_records_count = udf3.groupby(\"event_time\").agg(F.countDistinct(\"order_id\").alias(\"unique_order_ids\"))\n",
    "\n",
    "# Filter for records where the count of unique order_id values is greater than 1\n",
    "inconsistent_records_count = inconsistent_records_count.filter(inconsistent_records_count[\"unique_order_ids\"] > 1)\n",
    "\n",
    "# Count the number of inconsistent records\n",
    "\n",
    "num_inconsistent_records_1 = inconsistent_records_count.count()\n",
    "\n",
    "# Display the number of inconsistent records\n",
    "print(\"Number of inconsistent records:\", num_inconsistent_records_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba91845-ab65-4f02-a41e-a37578e30c9e",
   "metadata": {},
   "source": [
    "# remove the inconsistent records from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb5448d8-06f7-4e9b-8d61-675c4531598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+---------------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|    brand| price|        user_id|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+---------------+\n",
      "|2020-01-05 10:24:34|2348708941174670206|2273948316532212462|2268105428166508982|electronics.smart...|   huawei|254.61|911562541913251|\n",
      "|2020-01-05 10:28:15|2348709292439241205|2273948218930758560|2268105430162997728|electronics.audio...|  samsung| 12.71|911562541934771|\n",
      "|2020-01-05 10:28:15|2348709292439241205|1515966223509117074|2268105427872907696|               other|  samsung| 30.07|911562541934771|\n",
      "|2020-01-05 10:28:15|2348709292439241205|1515966223509255474|2268105392070329020|appliances.enviro...|    tefal|115.72|911562541934771|\n",
      "|2020-01-05 10:28:15|2348709292439241205|1515966223509089449|2268105428166508982|electronics.smart...|  samsung|138.63|911562541934771|\n",
      "|2020-01-05 10:18:52|2348709481015148897|2273948227654910594|2268105392070329020|appliances.enviro...|  samsung|104.14|911562541946200|\n",
      "|2020-01-05 10:18:52|2348709481015148897|1515966223509106786|2268105428166508982|electronics.smart...|  samsung|138.87|911562541946200|\n",
      "|2020-01-05 10:18:52|2348709481015148897|1515966223523303307|2374498913999872413|electronics.smart...|     awax|  5.56|911562541946200|\n",
      "|2020-01-05 10:18:52|2348709481015148897|2273948226103018251|2374498913999872445|electronics.video.tv|   megogo| 10.42|911562541946200|\n",
      "|2020-01-05 10:06:25|2348709507741254121|1515966223511666418|2268105635381903388|               other|technodom|  0.46|911562541918338|\n",
      "|2020-01-05 10:06:25|2348709507741254121|1515966223509380612|2268105635381903388|               other|technodom|  0.46|911562541918338|\n",
      "|2020-01-05 10:06:25|2348709507741254121|1515966223510073412|2268105635381903388|               other|technodom|  0.46|911562541918338|\n",
      "|2020-01-05 10:06:25|2348709507741254121|1515966223511666419|2268105635381903388|               other|technodom|  0.46|911562541918338|\n",
      "|2020-01-05 10:00:14|2348709538502279799|1515966223509298224|2268105407144657892|     accessories.bag| rivacase| 28.91|911562541901488|\n",
      "|2020-01-05 09:55:20|2348709636011458637|2273948316490269348|2268105428166508982|electronics.smart...|  samsung|173.13|911562541950220|\n",
      "|2020-01-05 09:55:20|2348709636011458637|1515966223509117074|2268105427872907696|               other|  samsung| 30.07|911562541950220|\n",
      "|2020-01-05 09:57:48|2348709639736000603|1515966223509117074|2268105427872907696|               other|  samsung| 30.07|911562541912375|\n",
      "|2020-01-05 09:57:48|2348709639736000603|2273948186349404174|2268105494268740422|               other|      neo| 30.07|911562541912375|\n",
      "|2020-01-05 09:57:48|2348709639736000603|1515966223509131886|2268105427075989918|               other|      ava|  2.78|911562541912375|\n",
      "|2020-01-05 09:57:48|2348709639736000603|2273948316473492113|2268105428166508982|electronics.smart...|  samsung|162.01|911562541912375|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+---------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FilterInconsistentRecords\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data - replace this with your actual DataFrame\n",
    "# cdf1 = spark.createDataFrame([...], [\"event_time\", \"order_id\", ...])\n",
    "\n",
    "# Identify event_time values with more than one unique order_id\n",
    "inconsistent_event_times = udf3.groupBy(\"event_time\").agg(F.countDistinct(\"order_id\").alias(\"unique_order_ids\")) \\\n",
    "                               .where(\"unique_order_ids > 1\") \\\n",
    "                               .select(\"event_time\")\n",
    "\n",
    "# Inner join to filter out inconsistent records\n",
    "udf4 = udf3.join(inconsistent_event_times, \"event_time\", \"left_anti\")\n",
    "\n",
    "# Show the DataFrame\n",
    "udf4.show()\n",
    "\n",
    "# Stop SparkSession\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "158674cf-6181-4704-9445-07fb21886820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 183:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1778444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row_count = udf4.count()\n",
    "\n",
    "print(row_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6ce2580-2bce-4c10-8ddd-620b005e592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 202:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent records: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Group by event_time and count the distinct order_id values\n",
    "inconsistent_records_count = udf4.groupby(\"event_time\").agg(F.countDistinct(\"order_id\").alias(\"unique_order_ids\"))\n",
    "\n",
    "# Filter for records where the count of unique order_id values is greater than 1\n",
    "inconsistent_records_count = inconsistent_records_count.filter(inconsistent_records_count[\"unique_order_ids\"] > 1)\n",
    "\n",
    "# Count the number of inconsistent records\n",
    "\n",
    "num_inconsistent_records_1 = inconsistent_records_count.count()\n",
    "\n",
    "# Display the number of inconsistent records\n",
    "print(\"Number of inconsistent records:\", num_inconsistent_records_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0970e763-8b4b-4d7a-b02f-631a2839cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 215:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent records: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Group by order_id and count the distinct event_time values\n",
    "inconsistent_records_count = udf4.groupby(\"order_id\").agg(F.countDistinct(\"event_time\").alias(\"unique_event_times\"))\n",
    "\n",
    "# Filter for records where the count of unique event_time values is greater than 1\n",
    "inconsistent_records_count = inconsistent_records_count.filter(inconsistent_records_count[\"unique_event_times\"] > 1)\n",
    "\n",
    "# Count the number of inconsistent records\n",
    "num_inconsistent_records = inconsistent_records_count.count()\n",
    "\n",
    "# Display the number of inconsistent records\n",
    "print(\"Number of inconsistent records:\", num_inconsistent_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e754a-4895-4d5a-b568-f3a4d6aa9664",
   "metadata": {},
   "source": [
    "# Download file after removing inconsistent records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbd2d6e8-4fde-473a-a747-abdddfe36460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"udf4_file\"\n",
    "\n",
    "udf4.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e5bd1-7174-4782-a025-55494fbeda14",
   "metadata": {},
   "source": [
    "# Counf unique Order IDs (after removing inconsistent records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53586886-ec35-45e2-bc1d-6064837188be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/14 22:55:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:55:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 262:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order_id values: 1176381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = udf4.select(countDistinct(\"order_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order_id values:\", uc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d955f-4a97-469d-8810-b2352b50e8b4",
   "metadata": {},
   "source": [
    "# Counf unique Event time (after removing inconsistent records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f7dd49c-2239-43b3-88ea-e26445a9198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/14 22:55:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:55:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:55:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/02/14 22:55:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 249:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique event_time values: 1176381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "unique_user_count = udf4.select(countDistinct(\"event_time\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique event_time values:\", unique_user_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49d2b5-478d-4b52-a4e3-ec9956736930",
   "metadata": {},
   "source": [
    "# Data cleaning after Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9d1160-3608-4dc7-b428-fee8bd5ba10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/hadoop/.local/lib/python3.10/site-packages (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 15:05:51 WARN Utils: Your hostname, tejasshinde-Nitro-AN515-55 resolves to a loopback address: 127.0.1.1; using 192.168.1.155 instead (on interface wlp0s20f3)\n",
      "24/02/15 15:05:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/15 15:05:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2f21c-fb55-4e2b-9626-22b38b77307d",
   "metadata": {},
   "source": [
    "# Upload partial clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4f5a5d-83ef-43b5-8990-8b68ec4e0aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"other_clean.csv\"\n",
    "ocdf = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d28dd5-b64b-4149-8830-3e8864368973",
   "metadata": {},
   "source": [
    "# Count total no. of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61db8c50-5789-42ee-8c45-619dceec90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088263\n"
     ]
    }
   ],
   "source": [
    "rec_cnt = ocdf.count()\n",
    "print(rec_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a12c05-16fa-44f1-8739-e9effbe43afa",
   "metadata": {},
   "source": [
    "# check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8a1462-7372-45a1-8866-5d95c6985d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|         0|       0|         0|          0|            0|    0|    0|1551952|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in ocdf.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = ocdf.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f6140-d396-44a8-b850-5903e6db215b",
   "metadata": {},
   "source": [
    "# Drop null users so that users can be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7c510c-f2cc-4e72-b838-919eddbed7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 12:44:48 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RemoveNullUserIDs\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "drpusr = ocdf.dropna(subset=[\"user_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e3514db-ee25-4e8f-a19a-7aee4a25f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rec_cnt = drpusr.count()\n",
    "print(rec_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f83cf-cf83-4d4c-8f96-b5c9912b3fa3",
   "metadata": {},
   "source": [
    "# Download file after removing null users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed9fcdd-dc3f-4a42-8d2b-89d97b284d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drpusr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhase1/drop_user.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdrpusr\u001b[49m\u001b[38;5;241m.\u001b[39mcoalesce(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mcsv(output_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'drpusr' is not defined"
     ]
    }
   ],
   "source": [
    "output_path = \"Phase1/drop_user\"\n",
    "\n",
    "drpusr.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a84c3e-08e2-48ed-8b8a-31fe364a2864",
   "metadata": {},
   "source": [
    "# Load drop_user file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e41f94-b002-45c3-8140-608a8d16e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"Phase1/drop_user.csv\"\n",
    "drpusr = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ccd466-8633-4b8d-b7fb-74c1611cb91e",
   "metadata": {},
   "source": [
    "# Count unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf4eb9bb-6c8e-47ae-9733-b44d4f6ec8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user values: 229228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = drpusr.select(countDistinct(\"user_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique user values:\", uc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40ac49-1d1c-4b06-99b1-02fb3e0e0bd2",
   "metadata": {},
   "source": [
    "# Count unique orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105a5a8f-b951-4322-94f7-8198516d9260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs values: 389511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = drpusr.select(countDistinct(\"order_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order IDs values:\", uc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e95e99-de24-47ef-897f-1a07ec4accc1",
   "metadata": {},
   "source": [
    "# Count unique event times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07b836cb-731e-4f59-a281-627bbe9be26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique event times: 379353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = drpusr.select(countDistinct(\"event_time\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique event times:\", uc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e2e6a-b7fd-4b86-b156-20e963e81768",
   "metadata": {},
   "source": [
    "# Calculate the total amount spent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ce9bd-69fa-41d1-bece-3bdb2c84e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TotalAmount\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "total_amount = drpusr.select(sum(col(\"price\"))).collect()[0][0]\n",
    "\n",
    "print(\"Total amount spent:\", total_amount)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec880b-6dab-4698-a7dd-3ed47f2f84c8",
   "metadata": {},
   "source": [
    "# Max spent by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fbf50b1-8242-4ae5-b0c9-b6c9f7bbf1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 15:42:37 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max spent: 11574.05\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MaxAvgAmountSpent\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "max = drpusr.agg(max(\"price\")).collect()[0][0]\n",
    "\n",
    "print(\"Max spent:\", max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d836f562-eef3-4ed4-9f00-29539242e0e0",
   "metadata": {},
   "source": [
    "# Min and Mean spent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b90fb0d-236f-43bd-a301-d59a36fa7e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 15:44:23 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min spent: 0.0\n",
      "Mean spent: 214.5357087772056\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, mean\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StatisticsAvgAmountSpent\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# Find the minimum and mean values of the column avg_amount_spent\n",
    "statistics = drpusr.agg(min(\"price\"), mean(\"price\")).collect()[0]\n",
    "\n",
    "# Extract the minimum and mean values\n",
    "min = statistics[0]\n",
    "mean = statistics[1]\n",
    "\n",
    "# Print the minimum and mean values\n",
    "print(\"Min spent:\", min)\n",
    "print(\"Mean spent:\", mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651fc4e7-11ac-45c5-a342-7044fa4baf9c",
   "metadata": {},
   "source": [
    "# Create new dataframe : Average amount spent by each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2afd98c-d8bc-4470-86d0-c6230bb9d460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|            user_id|  avg_amount_spent|\n",
      "+-------------------+------------------+\n",
      "|1515915625484582166|           27.4675|\n",
      "|1515915625484624152|              6.92|\n",
      "|1515915625456673752|            254.61|\n",
      "|1515915625456170778|195.07857142857142|\n",
      "|1515915625464630612|154.53615384615384|\n",
      "|1515915625448144030|            115.72|\n",
      "|1515915625456384238|             74.05|\n",
      "|1515915625450815072|             20.81|\n",
      "|1515915625474388138|116.17999999999999|\n",
      "|1515915625454286948|196.40571428571428|\n",
      "|1515915625464215439|            601.83|\n",
      "|1515915625484623565|333.80125000000004|\n",
      "|1515915625456780260|147.08333333333331|\n",
      "|1515915625484629937|             84.93|\n",
      "|1515915625484623070|            297.43|\n",
      "|1515915625472058435|             25.44|\n",
      "|1515915625463925870|            624.98|\n",
      "|1515915625459124510|           154.375|\n",
      "|1515915625484654720|            25.555|\n",
      "|1515915625484645344|           167.805|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AverageAmountSpent\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "avgamt = drpusr.groupBy(\"user_id\").agg(avg(\"price\").alias(\"avg_amount_spent\"))\n",
    "\n",
    "avgamt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a99cfa-cb77-462f-81f8-b2ca9f1a3382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount spent: 51361913.93574576\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TotalAmount\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "total_amount = avgamt.select(sum(col(\"avg_amount_spent\"))).collect()[0][0]\n",
    "\n",
    "print(\"Total amount spent:\", total_amount)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70561817-ba99-4900-b887-dff632d3ca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229228\n"
     ]
    }
   ],
   "source": [
    "rc = avgamt.count()\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9c2fc5-e4c3-410e-879b-516100c053fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"Phase1/avg_amt_spent\"\n",
    "\n",
    "avgamt.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d7c8d-024f-49aa-81d4-6fb9e6a79518",
   "metadata": {},
   "source": [
    "# Find the maximum value of the column avg_amount_spent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0541ba37-b52f-4591-8f67-b7a6d13ab9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value of avg_amount_spent: 9606.48\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MaxAvgAmountSpent\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "max = avgamt.agg(max(\"avg_amount_spent\")).collect()[0][0]\n",
    "\n",
    "print(\"Max value of avg_amount_spent:\", max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1a59d71-3780-4d35-aeba-33c07c8c8b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 15:25:56 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "[Stage 31:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value of avg_amount_spent: 0.0\n",
      "Mean value of avg_amount_spent: 224.0647474817464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, mean\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StatisticsAvgAmountSpent\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# Find the minimum and mean values of the column avg_amount_spent\n",
    "statistics = avgamt.agg(min(\"avg_amount_spent\"), mean(\"avg_amount_spent\")).collect()[0]\n",
    "\n",
    "# Extract the minimum and mean values\n",
    "min = statistics[0]\n",
    "mean = statistics[1]\n",
    "\n",
    "# Print the minimum and mean values\n",
    "print(\"Min value of avg_amount_spent:\", min)\n",
    "print(\"Mean value of avg_amount_spent:\", mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f637eb-a28e-43ea-89c5-84da3e2a61bd",
   "metadata": {},
   "source": [
    "# No. of users who spent 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72495f82-bd3b-489e-875e-6a8a8316816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users who spent 0: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CountUsersSpentZero\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Count the number of users who spent 0\n",
    "users_spent_zero = avgamt.filter(avgamt[\"avg_amount_spent\"] == 0).select(\"user_id\").distinct().count()\n",
    "\n",
    "# Print the number of users who spent 0\n",
    "print(\"Number of users who spent 0:\", users_spent_zero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b9735-8c5d-4cb6-9704-7eade92e7ad2",
   "metadata": {},
   "source": [
    "# Count distinct category in drop_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f5a800c-74de-4341-a5f8-9cf10b29ff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct records before the first dot '.': 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# Extract the category before the first dot '.'\n",
    "df_with_category = drpusr.withColumn(\"category_before_dot\", split(col(\"category_code\"), \"\\\\.\")[0])\n",
    "\n",
    "# Count the distinct records before the first dot '.'\n",
    "distinct_category_before_dot_count = df_with_category.select(\"category_before_dot\").distinct().count()\n",
    "\n",
    "# Display the count of distinct records before the first dot '.'\n",
    "print(\"Number of distinct records before the first dot '.':\", distinct_category_before_dot_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ed48a8-e849-4b53-bb8c-089b4664bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct names of records before the first dot '.' in the 'category_code' column:\n",
      "medicine\n",
      "computers\n",
      "auto\n",
      "stationery\n",
      "sport\n",
      "other\n",
      "apparel\n",
      "appliances\n",
      "country_yard\n",
      "furniture\n",
      "accessories\n",
      "kids\n",
      "electronics\n",
      "construction\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# Extract the category before the first dot '.'\n",
    "df_with_category = drpusr.withColumn(\"category_before_dot\", split(col(\"category_code\"), \"\\\\.\")[0])\n",
    "\n",
    "# Select and display the distinct names of records before the first dot '.'\n",
    "distinct_category_before_dot_names = df_with_category.select(\"category_before_dot\").distinct().collect()\n",
    "distinct_category_before_dot_names = [row[\"category_before_dot\"] for row in distinct_category_before_dot_names]\n",
    "\n",
    "# Display the distinct names of records before the first dot '.'\n",
    "print(\"Distinct names of records before the first dot '.' in the 'category_code' column:\")\n",
    "for name in distinct_category_before_dot_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d6dbf-6f73-47e4-9964-19b6afca3b56",
   "metadata": {},
   "source": [
    "# Load category data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "229993d6-0045-4a6e-9dad-1e08189266cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"category.csv\"\n",
    "cat = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a28c8608-d919-442a-9deb-930346ed4275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "|         event_time|  order_id|product_id|category_id|       category_code|  brand| price|            user_id|   category|\n",
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "|2020-04-29 20:11:49|2.29807E18|1.51597E18| 2.26811E18|computers.periphe...|     hp|152.52|1515915625443020000|  computers|\n",
      "|2020-04-29 23:42:11|2.29818E18|1.51597E18| 2.26811E18|electronics.audio...|samsung|  8.08|1515915625445930000|electronics|\n",
      "|2020-04-30 18:01:51|2.29873E18|1.51597E18| 2.36074E18|appliances.enviro...|   beko|231.46|1515915625446610000| appliances|\n",
      "|2020-04-30 19:27:36|2.29877E18|1.51597E18| 2.26811E18|electronics.audio...|  razer|104.14|1515915625452720000|electronics|\n",
      "|2020-04-30 21:37:48|2.29884E18|1.51597E18| 2.26811E18|electronics.audio...|philips| 32.38|1515915625452810000|electronics|\n",
      "|2020-05-01 12:54:33| 2.2993E18|1.51597E18| 2.26811E18|computers.periphe...|  delux|   6.0|1515915625452840000|  computers|\n",
      "|2020-05-01 22:40:42|2.29959E18|1.51597E18| 2.26811E18|electronics.audio...|samsung|  8.08|1515915625441990000|electronics|\n",
      "|2020-05-02 23:25:58|2.30034E18|2.27395E18| 2.26811E18|computers.periphe...|  delux|  5.07|1515915625444060000|  computers|\n",
      "|2020-05-04 07:07:11| 2.3013E18|1.51597E18| 2.26811E18|  stationery.battery|  varta|  0.69|1515915625452090000| stationery|\n",
      "|2020-05-06 08:37:23|2.30279E18|1.51597E18| 2.26811E18|electronics.audio...|  trust| 19.65|1515915625455530000|electronics|\n",
      "|2020-05-06 11:40:59|2.30289E18|1.51597E18| 2.26811E18|appliances.kitche...|    ava|  9.24|1515915625455410000| appliances|\n",
      "|2020-05-06 18:58:35|2.30311E18|2.27395E18| 2.26811E18|appliances.kitche...|polaris| 30.07|1515915625454910000| appliances|\n",
      "|2020-05-07 17:06:03|2.30377E18|1.51597E18| 2.26811E18|electronics.smart...| huawei|277.75|1515915625455260000|electronics|\n",
      "|2020-05-07 17:42:39|2.30379E18|1.51597E18| 2.26811E18|electronics.audio...| xiaomi| 25.44|1515915625455330000|electronics|\n",
      "|2020-05-08 00:34:21|  2.304E18|1.51597E18| 2.26811E18|         kids.skates|ninebot|608.77|1515915625454600000|       kids|\n",
      "|2020-05-09 06:14:01| 2.3049E18|1.51597E18| 2.36074E18|appliances.enviro...|   beko|266.18|1515915625457040000| appliances|\n",
      "|2020-05-10 14:59:23|2.30589E18|2.27395E18| 2.26811E18|computers.network...|  altel| 57.85|1515915625497420000|  computers|\n",
      "|2020-05-10 19:13:40|2.30601E18|1.51597E18| 2.26811E18|electronics.smart...| huawei|127.29|1515915625457680000|electronics|\n",
      "|2020-05-10 19:37:46|2.30603E18|1.51597E18| 2.26811E18|computers.periphe...|   none|  2.75|1515915625455930000|  computers|\n",
      "|2020-05-11 08:18:33|2.30641E18|1.51597E18| 2.26811E18|appliances.kitche...|indesit|198.13|1515915625457590000| appliances|\n",
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa5688ba-07e1-46d8-a3b3-45647b541190",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cat.drop('category_before_dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77ce026a-4ad3-4e58-8744-5b473332ed4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "|         event_time|  order_id|product_id|category_id|       category_code|  brand| price|            user_id|   category|\n",
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "|2020-04-29 20:11:49|2.29807E18|1.51597E18| 2.26811E18|computers.periphe...|     hp|152.52|1515915625443020000|  computers|\n",
      "|2020-04-29 23:42:11|2.29818E18|1.51597E18| 2.26811E18|electronics.audio...|samsung|  8.08|1515915625445930000|electronics|\n",
      "|2020-04-30 18:01:51|2.29873E18|1.51597E18| 2.36074E18|appliances.enviro...|   beko|231.46|1515915625446610000| appliances|\n",
      "|2020-04-30 19:27:36|2.29877E18|1.51597E18| 2.26811E18|electronics.audio...|  razer|104.14|1515915625452720000|electronics|\n",
      "|2020-04-30 21:37:48|2.29884E18|1.51597E18| 2.26811E18|electronics.audio...|philips| 32.38|1515915625452810000|electronics|\n",
      "|2020-05-01 12:54:33| 2.2993E18|1.51597E18| 2.26811E18|computers.periphe...|  delux|   6.0|1515915625452840000|  computers|\n",
      "|2020-05-01 22:40:42|2.29959E18|1.51597E18| 2.26811E18|electronics.audio...|samsung|  8.08|1515915625441990000|electronics|\n",
      "|2020-05-02 23:25:58|2.30034E18|2.27395E18| 2.26811E18|computers.periphe...|  delux|  5.07|1515915625444060000|  computers|\n",
      "|2020-05-04 07:07:11| 2.3013E18|1.51597E18| 2.26811E18|  stationery.battery|  varta|  0.69|1515915625452090000| stationery|\n",
      "|2020-05-06 08:37:23|2.30279E18|1.51597E18| 2.26811E18|electronics.audio...|  trust| 19.65|1515915625455530000|electronics|\n",
      "|2020-05-06 11:40:59|2.30289E18|1.51597E18| 2.26811E18|appliances.kitche...|    ava|  9.24|1515915625455410000| appliances|\n",
      "|2020-05-06 18:58:35|2.30311E18|2.27395E18| 2.26811E18|appliances.kitche...|polaris| 30.07|1515915625454910000| appliances|\n",
      "|2020-05-07 17:06:03|2.30377E18|1.51597E18| 2.26811E18|electronics.smart...| huawei|277.75|1515915625455260000|electronics|\n",
      "|2020-05-07 17:42:39|2.30379E18|1.51597E18| 2.26811E18|electronics.audio...| xiaomi| 25.44|1515915625455330000|electronics|\n",
      "|2020-05-08 00:34:21|  2.304E18|1.51597E18| 2.26811E18|         kids.skates|ninebot|608.77|1515915625454600000|       kids|\n",
      "|2020-05-09 06:14:01| 2.3049E18|1.51597E18| 2.36074E18|appliances.enviro...|   beko|266.18|1515915625457040000| appliances|\n",
      "|2020-05-10 14:59:23|2.30589E18|2.27395E18| 2.26811E18|computers.network...|  altel| 57.85|1515915625497420000|  computers|\n",
      "|2020-05-10 19:13:40|2.30601E18|1.51597E18| 2.26811E18|electronics.smart...| huawei|127.29|1515915625457680000|electronics|\n",
      "|2020-05-10 19:37:46|2.30603E18|1.51597E18| 2.26811E18|computers.periphe...|   none|  2.75|1515915625455930000|  computers|\n",
      "|2020-05-11 08:18:33|2.30641E18|1.51597E18| 2.26811E18|appliances.kitche...|indesit|198.13|1515915625457590000| appliances|\n",
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566314b3-4313-441b-91ab-38397174ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chagnge datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaf1a001-b863-4064-ba6f-311ed35ffe4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'double'),\n",
       " ('product_id', 'double'),\n",
       " ('category_id', 'double'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint'),\n",
       " ('category', 'string')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "656d4ba0-df87-4be9-b00a-2af837bedb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = cat.withColumn(\"user_id\", col(\"user_id\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d04f5353-7716-4cfc-a62c-4be1e42a05c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'double'),\n",
       " ('product_id', 'double'),\n",
       " ('category_id', 'double'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'string'),\n",
       " ('category', 'string')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6156106c-d625-4134-8489-a9fbb8093646",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = cat1.withColumn(\"order_id\", col(\"order_id\").cast(\"string\"))\n",
    "cat1 = cat1.withColumn(\"product_id\", col(\"product_id\").cast(\"string\"))\n",
    "cat1 = cat1.withColumn(\"category_id\", col(\"category_id\").cast(\"string\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0aaba3b-465f-414e-8cec-9e8b38d9bd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'string'),\n",
       " ('product_id', 'string'),\n",
       " ('category_id', 'string'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'string'),\n",
       " ('category', 'string')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "105d27c9-9737-4141-83f8-9c9dd4b49d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"Phase1/Cat1\"\n",
    "\n",
    "cat.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79a3e550-6c3b-4420-bf05-e720a53ab5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c03f63e-eb92-4acb-ada8-fe80c3896269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'double'),\n",
       " ('product_id', 'double'),\n",
       " ('category_id', 'double'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint'),\n",
       " ('category', 'string')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "179d336b-3700-4b0f-924a-62c2a5ac0ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "|         event_time|  order_id|product_id|category_id|       category_code|  brand| price|            user_id|   category|\n",
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "|2020-04-29 20:11:49|2.29807E18|1.51597E18| 2.26811E18|computers.periphe...|     hp|152.52|1515915625443020000|  computers|\n",
      "|2020-04-29 23:42:11|2.29818E18|1.51597E18| 2.26811E18|electronics.audio...|samsung|  8.08|1515915625445930000|electronics|\n",
      "|2020-04-30 18:01:51|2.29873E18|1.51597E18| 2.36074E18|appliances.enviro...|   beko|231.46|1515915625446610000| appliances|\n",
      "|2020-04-30 19:27:36|2.29877E18|1.51597E18| 2.26811E18|electronics.audio...|  razer|104.14|1515915625452720000|electronics|\n",
      "|2020-04-30 21:37:48|2.29884E18|1.51597E18| 2.26811E18|electronics.audio...|philips| 32.38|1515915625452810000|electronics|\n",
      "|2020-05-01 12:54:33| 2.2993E18|1.51597E18| 2.26811E18|computers.periphe...|  delux|   6.0|1515915625452840000|  computers|\n",
      "|2020-05-01 22:40:42|2.29959E18|1.51597E18| 2.26811E18|electronics.audio...|samsung|  8.08|1515915625441990000|electronics|\n",
      "|2020-05-02 23:25:58|2.30034E18|2.27395E18| 2.26811E18|computers.periphe...|  delux|  5.07|1515915625444060000|  computers|\n",
      "|2020-05-04 07:07:11| 2.3013E18|1.51597E18| 2.26811E18|  stationery.battery|  varta|  0.69|1515915625452090000| stationery|\n",
      "|2020-05-06 08:37:23|2.30279E18|1.51597E18| 2.26811E18|electronics.audio...|  trust| 19.65|1515915625455530000|electronics|\n",
      "|2020-05-06 11:40:59|2.30289E18|1.51597E18| 2.26811E18|appliances.kitche...|    ava|  9.24|1515915625455410000| appliances|\n",
      "|2020-05-06 18:58:35|2.30311E18|2.27395E18| 2.26811E18|appliances.kitche...|polaris| 30.07|1515915625454910000| appliances|\n",
      "|2020-05-07 17:06:03|2.30377E18|1.51597E18| 2.26811E18|electronics.smart...| huawei|277.75|1515915625455260000|electronics|\n",
      "|2020-05-07 17:42:39|2.30379E18|1.51597E18| 2.26811E18|electronics.audio...| xiaomi| 25.44|1515915625455330000|electronics|\n",
      "|2020-05-08 00:34:21|  2.304E18|1.51597E18| 2.26811E18|         kids.skates|ninebot|608.77|1515915625454600000|       kids|\n",
      "|2020-05-09 06:14:01| 2.3049E18|1.51597E18| 2.36074E18|appliances.enviro...|   beko|266.18|1515915625457040000| appliances|\n",
      "|2020-05-10 14:59:23|2.30589E18|2.27395E18| 2.26811E18|computers.network...|  altel| 57.85|1515915625497420000|  computers|\n",
      "|2020-05-10 19:13:40|2.30601E18|1.51597E18| 2.26811E18|electronics.smart...| huawei|127.29|1515915625457680000|electronics|\n",
      "|2020-05-10 19:37:46|2.30603E18|1.51597E18| 2.26811E18|computers.periphe...|   none|  2.75|1515915625455930000|  computers|\n",
      "|2020-05-11 08:18:33|2.30641E18|1.51597E18| 2.26811E18|appliances.kitche...|indesit|198.13|1515915625457590000| appliances|\n",
      "+-------------------+----------+----------+-----------+--------------------+-------+------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5815d529-7bbf-403a-975e-ce7d4779c05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'double'),\n",
       " ('product_id', 'double'),\n",
       " ('category_id', 'double'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint'),\n",
       " ('category', 'string')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "918ea866-4481-4f6d-b1a2-ddc234c49127",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cat.withColumn(\"order_id\", col(\"order_id\").cast(\"bigint\"))\n",
    "cat = cat.withColumn(\"product_id\", col(\"product_id\").cast(\"bigint\"))\n",
    "cat = cat.withColumn(\"category_id\", col(\"category_id\").cast(\"bigint\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ce2a1ae3-3c32-47b9-8898-4b11eb5146a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'bigint'),\n",
       " ('product_id', 'bigint'),\n",
       " ('category_id', 'bigint'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6921803d-6945-4e57-8749-afacaca357cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_time', 'timestamp'),\n",
       " ('order_id', 'bigint'),\n",
       " ('product_id', 'bigint'),\n",
       " ('category_id', 'bigint'),\n",
       " ('category_code', 'string'),\n",
       " ('brand', 'string'),\n",
       " ('price', 'double'),\n",
       " ('user_id', 'bigint'),\n",
       " ('category', 'string')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cecc6be5-afa8-4be9-9009-d41ff8b64532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-----------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|   category|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-----------+\n",
      "|2020-04-29 20:11:49|2298070000000000000|1515970000000000000|2268110000000000000|computers.periphe...|     hp|152.52|1515915625443020000|  computers|\n",
      "|2020-04-29 23:42:11|2298180000000000000|1515970000000000000|2268110000000000000|electronics.audio...|samsung|  8.08|1515915625445930000|electronics|\n",
      "|2020-04-30 18:01:51|2298730000000000000|1515970000000000000|2360740000000000000|appliances.enviro...|   beko|231.46|1515915625446610000| appliances|\n",
      "|2020-04-30 19:27:36|2298770000000000000|1515970000000000000|2268110000000000000|electronics.audio...|  razer|104.14|1515915625452720000|electronics|\n",
      "|2020-04-30 21:37:48|2298840000000000000|1515970000000000000|2268110000000000000|electronics.audio...|philips| 32.38|1515915625452810000|electronics|\n",
      "|2020-05-01 12:54:33|2299300000000000000|1515970000000000000|2268110000000000000|computers.periphe...|  delux|   6.0|1515915625452840000|  computers|\n",
      "|2020-05-01 22:40:42|2299590000000000000|1515970000000000000|2268110000000000000|electronics.audio...|samsung|  8.08|1515915625441990000|electronics|\n",
      "|2020-05-02 23:25:58|2300340000000000000|2273950000000000000|2268110000000000000|computers.periphe...|  delux|  5.07|1515915625444060000|  computers|\n",
      "|2020-05-04 07:07:11|2301300000000000000|1515970000000000000|2268110000000000000|  stationery.battery|  varta|  0.69|1515915625452090000| stationery|\n",
      "|2020-05-06 08:37:23|2302790000000000000|1515970000000000000|2268110000000000000|electronics.audio...|  trust| 19.65|1515915625455530000|electronics|\n",
      "|2020-05-06 11:40:59|2302890000000000000|1515970000000000000|2268110000000000000|appliances.kitche...|    ava|  9.24|1515915625455410000| appliances|\n",
      "|2020-05-06 18:58:35|2303110000000000000|2273950000000000000|2268110000000000000|appliances.kitche...|polaris| 30.07|1515915625454910000| appliances|\n",
      "|2020-05-07 17:06:03|2303770000000000000|1515970000000000000|2268110000000000000|electronics.smart...| huawei|277.75|1515915625455260000|electronics|\n",
      "|2020-05-07 17:42:39|2303790000000000000|1515970000000000000|2268110000000000000|electronics.audio...| xiaomi| 25.44|1515915625455330000|electronics|\n",
      "|2020-05-08 00:34:21|2304000000000000000|1515970000000000000|2268110000000000000|         kids.skates|ninebot|608.77|1515915625454600000|       kids|\n",
      "|2020-05-09 06:14:01|2304900000000000000|1515970000000000000|2360740000000000000|appliances.enviro...|   beko|266.18|1515915625457040000| appliances|\n",
      "|2020-05-10 14:59:23|2305890000000000000|2273950000000000000|2268110000000000000|computers.network...|  altel| 57.85|1515915625497420000|  computers|\n",
      "|2020-05-10 19:13:40|2306010000000000000|1515970000000000000|2268110000000000000|electronics.smart...| huawei|127.29|1515915625457680000|electronics|\n",
      "|2020-05-10 19:37:46|2306030000000000000|1515970000000000000|2268110000000000000|computers.periphe...|   none|  2.75|1515915625455930000|  computers|\n",
      "|2020-05-11 08:18:33|2306410000000000000|1515970000000000000|2268110000000000000|appliances.kitche...|indesit|198.13|1515915625457590000| appliances|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eaf20782-c45d-431c-8527-074ed73bebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"Phase1/Cat\"\n",
    "\n",
    "cat.coalesce(1).write.csv(output_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1a248b20-e406-4073-9ee4-ebfb79b4afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536311\n"
     ]
    }
   ],
   "source": [
    "print(cat.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ac817172-a0e0-4923-97bd-34d070abe654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|event_time|order_id|product_id|category_id|category_code|brand|price|user_id|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "|         0|       0|         0|          0|            0|    0|    0|      0|\n",
      "+----------+--------+----------+-----------+-------------+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "null_counts = [F.sum(F.col(column).isNull().cast(\"integer\")).alias(column) for column in cat.columns]\n",
    "\n",
    "# Describe the DataFrame with null value counts\n",
    "null_counts_df = cat.agg(*null_counts)\n",
    "\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4d4c7d73-7932-446d-8406-9c8a84c9b06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 302:============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique event times: 379353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"event_time\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique event times:\", uc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b522fbad-bf8d-4291-a700-16e944eb0f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs: 389511\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"order_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order IDs:\", uc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec462db4-1405-46d2-a141-38e03028568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs: 389511\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"order_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order IDs:\", uc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9bf4b33c-53a1-4336-9f76-e8ae9694e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user IDs: 229228\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"user_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique user IDs:\", uc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bec0161a-edf6-429c-9f90-be7102a79c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs: 14\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"category\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order IDs:\", uc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3cc146a-3922-4e57-9d27-35ea9e00056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs: 124\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"category_code\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order IDs:\", uc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29b8cd32-3c53-4089-b4fe-ae215623cd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"category_FINAL.csv\"\n",
    "cat = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "335abdfe-8f43-4267-8a12-3670bea32314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs: 14\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"category\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order IDs:\", uc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81783813-392d-405f-9a4a-bb1183ea43f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-----------+\n",
      "|         event_time|           order_id|         product_id|        category_id|       category_code|  brand| price|            user_id|   category|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-----------+\n",
      "|2020-04-29 20:11:49|2298069964415828136|1515966223509122874|2268105407933187062|computers.periphe...|     hp|152.52|1515915625443027224|  computers|\n",
      "|2020-04-29 23:42:11|2298175846491357353|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625445938216|electronics|\n",
      "|2020-04-30 18:01:51|2298729326712980173|1515966223509089265|2360741866917331945|appliances.enviro...|   beko|231.46|1515915625446617606| appliances|\n",
      "|2020-04-30 19:27:36|2298772487720140990|1515966223509335414|2268105430162997728|electronics.audio...|  razer|104.14|1515915625452727322|electronics|\n",
      "|2020-04-30 21:37:48|2298838016631767159|1515966223509255514|2268105430162997728|electronics.audio...|philips| 32.38|1515915625452815830|electronics|\n",
      "|2020-05-01 12:54:33|2299299428894245316|1515966223509089826|2268105406549066706|computers.periphe...|  delux|   6.0|1515915625452840817|  computers|\n",
      "|2020-05-01 22:40:42|2299594452823442104|1515966223509122666|2268105430162997728|electronics.audio...|samsung|  8.08|1515915625441990819|electronics|\n",
      "|2020-05-02 23:25:58|2300342008322982139|2273948248047616169|2268105406549066706|computers.periphe...|  delux|  5.07|1515915625444068089|  computers|\n",
      "|2020-05-04 07:07:11|2301298926818427157|1515966223509351741|2268105419375247608|  stationery.battery|  varta|  0.69|1515915625452091416| stationery|\n",
      "|2020-05-06 08:37:23|2302793875086902264|1515966223509090254|2268105421933773102|electronics.audio...|  trust| 19.65|1515915625455538086|electronics|\n",
      "|2020-05-06 11:40:59|2302886286089781416|1515966223509089722|2268105441856717530|appliances.kitche...|    ava|  9.24|1515915625455413662| appliances|\n",
      "|2020-05-06 18:58:35|2303106530796372754|2273948216456118473|2268105440917193414|appliances.kitche...|polaris| 30.07|1515915625454919094| appliances|\n",
      "|2020-05-07 17:06:03|2303774668819006287|1515966223509104779|2268105428166508982|electronics.smart...| huawei|277.75|1515915625455260153|electronics|\n",
      "|2020-05-07 17:42:39|2303793094941737810|1515966223509104342|2268105430162997728|electronics.audio...| xiaomi| 25.44|1515915625455337062|electronics|\n",
      "|2020-05-08 00:34:21|2304000304833627082|1515966223509117177|2268105464766005446|         kids.skates|ninebot|608.77|1515915625454603469|       kids|\n",
      "|2020-05-09 06:14:01|2304896044028134084|1515966223509089293|2360741867017995243|appliances.enviro...|   beko|266.18|1515915625457040117| appliances|\n",
      "|2020-05-10 14:59:23|2305885242767966747|2273948308370096764|2268105409048870926|computers.network...|  altel| 57.85|1515915625497428278|  computers|\n",
      "|2020-05-10 19:13:40|2306013232357180361|1515966223509088510|2268105428166508982|electronics.smart...| huawei|127.29|1515915625457683949|electronics|\n",
      "|2020-05-10 19:37:46|2306025363609748437|1515966223509300544|2268105406691673046|computers.periphe...|   none|  2.75|1515915625455930757|  computers|\n",
      "|2020-05-11 08:18:33|2306408274540364573|1515966223509259282|2268105389956399770|appliances.kitche...|indesit|198.13|1515915625457596219| appliances|\n",
      "+-------------------+-------------------+-------------------+-------------------+--------------------+-------+------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "07e95736-e1e5-4236-aece-c08b07aac83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536311"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "10794ae6-0b26-4396-aa99-4740a43fc427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique order IDs: 19078\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Count the number of unique user_id values\n",
    "uc = cat.select(countDistinct(\"product_id\")).collect()[0][0]\n",
    "\n",
    "# Display the count of unique user_id values\n",
    "print(\"Number of unique order IDs:\", uc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
